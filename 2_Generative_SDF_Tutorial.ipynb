{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876ee20c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Neural Shape Model Tutorial #2\n",
    "\n",
    "## Generative Signed Distance Functions\n",
    "\n",
    "Building on Tutorial #1, we now explore **generative shape modeling** - training a \n",
    "single neural network that can represent multiple bone shapes and generate new variations!\n",
    "\n",
    "### üöÄ What's New in This Tutorial?\n",
    "\n",
    "**Tutorial #1** taught us to fit one neural network to **one** bone shape. \n",
    "**Tutorial #2** trains one network to represent **multiple** bone shapes using \n",
    "**latent codes**.\n",
    "\n",
    "### üß¨ Generative Shape Modeling Concepts\n",
    "\n",
    "**The Core Idea**: Instead of learning one specific shape, we learn a **shape space** - \n",
    "a continuous representation where:\n",
    "- Each point in the space represents a different bone shape\n",
    "- We can interpolate between shapes smoothly  \n",
    "- We can generate entirely new bone variations\n",
    "- All shapes share common anatomical structure\n",
    "\n",
    "### üîë Key Technical Innovations\n",
    "\n",
    "**1. Latent Embeddings**\n",
    "```\n",
    "Traditional: f(x,z) ‚Üí SDF\n",
    "Generative:  f(x,z,latent_code) ‚Üí SDF\n",
    "```\n",
    "- Each bone gets a unique **latent vector** (learnable shape code)\n",
    "- Network learns to decode coordinates + latent ‚Üí signed distance\n",
    "- Latent space captures shape variation patterns\n",
    "\n",
    "**2. Multi-Shape Training**\n",
    "- Load multiple tibia bones from different patients\n",
    "- Register them to common coordinate system\n",
    "- Train single network on all shapes simultaneously\n",
    "- Network learns shared shape patterns + individual variations\n",
    "\n",
    "**3. Shape Space Exploration**\n",
    "- Interpolate between latent codes ‚Üí morph between bone shapes\n",
    "- Generate new shapes by sampling latent space\n",
    "- Control specific shape characteristics\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you'll understand:\n",
    "1. **Latent embedding architectures** for generative modeling\n",
    "2. **Multi-shape registration** and normalization pipelines\n",
    "3. **Shared representation learning** across shape families\n",
    "4. **Shape interpolation and generation** techniques\n",
    "\n",
    "### üî¨ Applications\n",
    "\n",
    "- Statistical shape models for pathology detection\n",
    "- Patient-specific shape generation for surgical planning\n",
    "- Population-level shape analysis studies\n",
    "\n",
    "\n",
    "Let's start building our generative bone shape model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# ENVIRONMENT SETUP: Install required packages for generative shape modeling\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"üîß Setting up Google Colab environment for generative SDF tutorial...\")\n",
    "    \n",
    "    # Update core package management tools\n",
    "    %pip install --upgrade pip setuptools wheel\n",
    "    \n",
    "    # Download requirements specific to Colab environment\n",
    "    if not os.path.exists('requirements_colab.txt'):\n",
    "        print(\"üì¶ Downloading package requirements...\")\n",
    "        !wget https://raw.githubusercontent.com/gattia/ISB-2025-Shape-Modeling/main/requirements_colab.txt\n",
    "    \n",
    "    # Install all required packages for:\n",
    "    # - Mesh processing (pymskt, pyvista)\n",
    "    # - Neural networks (pytorch)\n",
    "    # - 3D visualization (itkwidgets)\n",
    "    # - Scientific computing (numpy, matplotlib)\n",
    "    print(\"‚öôÔ∏è Installing packages...\")\n",
    "    %pip install -r requirements_colab.txt\n",
    "    \n",
    "    print(\"‚úÖ Environment setup complete!\")\n",
    "else:\n",
    "    print(\"üè† Running in local environment - assuming packages are already installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# LIBRARY IMPORTS: Core tools for generative shape modeling\n",
    "# =============================================================================\n",
    "\n",
    "# Medical imaging and mesh processing\n",
    "import pymskt as mskt          # Advanced mesh operations and bone analysis tools\n",
    "import pyvista as pv           # 3D data processing and visualization\n",
    "from itkwidgets import view    # Interactive 3D visualization in Jupyter\n",
    "\n",
    "# Core Python libraries\n",
    "import glob                    # File path pattern matching for mesh loading\n",
    "import os                      # Operating system interface for file operations\n",
    "import json                    # JSON parsing for mesh file lists\n",
    "import sys                     # System-specific parameters and functions\n",
    "import math                    # Mathematical functions (for embedding initialization)\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np             # Numerical computing and array operations\n",
    "import matplotlib.pyplot as plt # Plotting and visualization\n",
    "\n",
    "# PyTorch deep learning framework\n",
    "import torch                   # Main PyTorch library for tensors and autograd\n",
    "import torch.nn as nn          # Neural network modules and loss functions\n",
    "from torch.utils.data import Dataset, DataLoader  # Data handling utilities for batch processing\n",
    "\n",
    "# Enable widget support for 3D visualization in Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    print(\"üì± Enabled 3D widget support for Google Colab\")\n",
    "\n",
    "print(\"üìö All libraries imported successfully!\")\n",
    "print(\"üéØ Ready for generative shape modeling with multiple tibia bones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4aedcd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Multi-Shape Data Loading\n",
    "\n",
    "### üîÑ From Single Shape to Shape Collection\n",
    "\n",
    "**Tutorial #1**: Loaded one tibia bone and learned its specific geometry  \n",
    "**Tutorial #2**: Load multiple tibia bones from different patients to learn shape variation patterns\n",
    "\n",
    "### üìä Dataset Structure\n",
    "\n",
    "Our dataset contains paired tibia bones from multiple patients:\n",
    "- **Left and right tibias** from the same individuals\n",
    "    - Left are already flipped to be rights\n",
    "- **Natural shape variation** representing population diversity\n",
    "\n",
    "### üéØ Why Multiple Shapes?\n",
    "\n",
    "**Shape Space Learning**: \n",
    "- Single shape ‚Üí Overfits to one specific geometry\n",
    "- Multiple shapes ‚Üí Learns shared anatomical patterns + individual variations\n",
    "- Network discovers what makes a \"tibia\" vs. patient-specific differences\n",
    "\n",
    "**Generative Capabilities**:\n",
    "- Can interpolate between existing patient shapes\n",
    "- Can generate new bone variations within learned distribution\n",
    "- Enables statistical shape analysis and population studies\n",
    "\n",
    "### üìÅ Data Management Strategy\n",
    "\n",
    "We use a JSON manifest file listing all available mesh files:\n",
    "- **Flexible loading**: Works both locally and in Colab\n",
    "- **Consistent naming**: Standardized file naming convention\n",
    "\n",
    "\n",
    "Let's load our bone collection and prepare for multi-shape modeling!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf84eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MESH COLLECTION LOADING: Prepare multiple bone shapes for generative training\n",
    "# =============================================================================\n",
    "\n",
    "# Detect environment: Colab (remote) vs local development\n",
    "is_colab = 'google.colab' in sys.modules\n",
    "print(f\"üåç Environment: {'Google Colab (remote)' if is_colab else 'Local development'}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MANIFEST FILE LOADING: Get list of all available mesh files\n",
    "# =============================================================================\n",
    "\n",
    "json_path = 'list_meshes.json'\n",
    "\n",
    "# Download mesh manifest if running in Colab\n",
    "if is_colab and not os.path.exists(json_path):\n",
    "    print(\"üìã Downloading mesh file manifest...\")\n",
    "    !wget https://raw.githubusercontent.com/gattia/ISB-2025-Shape-Modeling/main/list_meshes.json -O list_meshes.json\n",
    "\n",
    "# Load the complete list of available mesh filenames\n",
    "# This JSON contains all tibia bone files in the dataset\n",
    "with open(json_path, 'r') as f:\n",
    "    mesh_list = json.load(f)  # List of VTK filenames\n",
    "\n",
    "print(f\"üìä Total available bones in dataset: {len(mesh_list)}\")\n",
    "print(f\"üìÅ Mesh manifest: {json_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PATH PREPARATION: Build file paths for each environment\n",
    "# =============================================================================\n",
    "\n",
    "list_tib_paths = []\n",
    "\n",
    "for mesh_filename in mesh_list:\n",
    "    if is_colab:\n",
    "        # Remote: Construct URL for GitHub raw content access\n",
    "        base_url = \"https://raw.githubusercontent.com/gattia/ISB-2025-Shape-Modeling/main/data\"\n",
    "        path_tib_bone = f\"{base_url}/{mesh_filename}\"\n",
    "        \n",
    "    else:\n",
    "        # Local: Build path to local data directory\n",
    "        path_tib_bone = os.path.join('data', mesh_filename)\n",
    "        \n",
    "        # Skip if file doesn't exist locally (partial dataset)\n",
    "        if not os.path.exists(path_tib_bone):\n",
    "            print(f\"‚ö†Ô∏è Skipping missing file: {mesh_filename}\")\n",
    "            continue\n",
    "            \n",
    "    list_tib_paths.append(path_tib_bone)\n",
    "\n",
    "print(f\"‚úÖ Prepared {len(list_tib_paths)} bone file paths\")\n",
    "print(f\"üéØ Ready to load bone collection for generative modeling\")\n",
    "\n",
    "# Display first few filenames as examples\n",
    "print(f\"\\nüìã Example bone files:\")\n",
    "for i, filename in enumerate(mesh_list[:3]):\n",
    "    print(f\"   {i+1}. {filename}\")\n",
    "if len(mesh_list) > 3:\n",
    "    print(f\"   ... and {len(mesh_list)-3} more bones\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ef5f3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Shape Normalization and Registration\n",
    "\n",
    "### üéØ The Challenge: Aligning Multiple Bones\n",
    "\n",
    "When working with multiple bone shapes from different patients, we face several alignment challenges:\n",
    "\n",
    "- **Different positions**: Bones scanned at different locations in space\n",
    "- **Different orientations**: Varying bone rotations in the scanner\n",
    "- **Different sizes**: Natural variation in bone scale between patients\n",
    "- **Different coordinate systems**: Scanner-specific coordinate frameworks\n",
    "\n",
    "### üîß Our Normalization Strategy\n",
    "\n",
    "**1. Centering** üìç\n",
    "```python\n",
    "# Move each bone's center of mass to origin (0,0,0)\n",
    "bone.points -= mean_position\n",
    "```\n",
    "\n",
    "**2. Scaling** üìè  \n",
    "```python\n",
    "# Scale each bone to fit within unit sphere \n",
    "bone.points /= max_distance_from_origin\n",
    "```\n",
    "\n",
    "**3. Registration** üéØ\n",
    "```python\n",
    "# Rigidly align each bone to a reference shape\n",
    "bone.rigidly_register(reference_bone)\n",
    "```\n",
    "\n",
    "### üß† Why This Matters for Generative Learning\n",
    "\n",
    "**Consistent Coordinate Space**:\n",
    "- Network learns shape variation, not position/rotation differences\n",
    "- All bones occupy same spatial region ‚Üí better training efficiency\n",
    "- Latent codes capture anatomical differences, not pose differences\n",
    "\n",
    "**Numerical Stability**:\n",
    "- Coordinates in [-1, 1] range ‚Üí stable neural network training\n",
    "- Consistent scales ‚Üí gradient flow optimization  \n",
    "- Reduced condition number ‚Üí faster convergence\n",
    "\n",
    "**Shape Space Quality**:\n",
    "- Anatomically meaningful interpolations between shapes\n",
    "- Latent arithmetic: e.g., `\"large_bone\" - \"average\" + \"narrow\"` works correctly  \n",
    "- Better clustering of similar bone types in latent space\n",
    "\n",
    "### ‚öñÔ∏è The Buffer Parameter\n",
    "\n",
    "Notice our normalization uses a `buffer=0.2` parameter:\n",
    "- Ensures bones don't touch the boundary of [-1,1] cube\n",
    "- Provides spatial margin for SDF computation\n",
    "- Prevents edge effects during surface reconstruction\n",
    "\n",
    "Let's implement our normalization pipeline!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f632d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SHAPE NORMALIZATION FUNCTION: Standardize bone geometry for multi-shape learning\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_bone(bone, buffer=0.2):\n",
    "    \"\"\"\n",
    "    Normalize a bone mesh to a standardized coordinate system.\n",
    "    \n",
    "    This function performs spatial normalization essential for training \n",
    "    generative models on multiple bone shapes from different patients.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bone : mskt.mesh.Mesh or pyvista.PolyData\n",
    "        Input bone mesh to normalize (modified in-place)\n",
    "    buffer : float, default=0.2\n",
    "        Safety margin to keep bone away from unit cube boundaries\n",
    "        - 0.0 = bone touches [-1,1] cube faces  \n",
    "        - 0.2 = bone fits within [-0.8,0.8] cube\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Modifies the input bone mesh in-place\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Normalization steps:\n",
    "    1. Center: Translate center of mass to origin\n",
    "    2. Scale: Fit bone within unit sphere with buffer\n",
    "    \n",
    "    This ensures all bones occupy consistent spatial regions\n",
    "    while preserving relative shape proportions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: CENTER THE BONE AT ORIGIN\n",
    "    # Calculate center of mass (centroid) of all bone vertices\n",
    "    mean = np.mean(bone.points, axis=0)  # Shape: (3,) for [x, y, z]\n",
    "    \n",
    "    # Translate bone so its center is at (0, 0, 0)\n",
    "    bone.points -= mean\n",
    "    \n",
    "    # STEP 2: SCALE TO UNIT SPHERE WITH BUFFER\n",
    "    # Compute distance from origin for each vertex\n",
    "    norm = np.linalg.norm(bone.points, axis=1)  # Shape: (N,) distances\n",
    "    \n",
    "    # Find the furthest vertex from origin\n",
    "    max_norm = np.max(norm)\n",
    "    \n",
    "    # Scale so max distance is (1-buffer), keeping bone inside unit cube\n",
    "    # Example: buffer=0.2 ‚Üí max distance becomes 0.8\n",
    "    bone.points /= (max_norm / (1-buffer))\n",
    "    \n",
    "    # Result: Bone fits within [-0.8, 0.8]¬≥ cube when buffer=0.2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252d74",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Multi-Shape Loading and Registration\n",
    "\n",
    "### üéØ Building Our Bone Collection\n",
    "\n",
    "Now we'll load multiple tibia bones and align them into a consistent coordinate system. This is where generative modeling begins to differ significantly from single-shape fitting.\n",
    "\n",
    "### üîÑ Registration Pipeline\n",
    "\n",
    "**Key Steps**:\n",
    "1. **Load first bone** ‚Üí Use as reference template  \n",
    "2. **For each subsequent bone**:\n",
    "   - Load and normalize independently\n",
    "   - Rigidly register to reference bone\n",
    "   - Add to collection\n",
    "\n",
    "### üéØ Why Registration Matters\n",
    "\n",
    "**Without Registration**:\n",
    "```\n",
    "Bone A: Pointing up    ‚Üë\n",
    "Bone B: Pointing right ‚Üí  \n",
    "Bone C: Pointing down  ‚Üì\n",
    "```\n",
    "Network learns orientation differences, not shape differences!\n",
    "\n",
    "**With Registration**:\n",
    "```\n",
    "Bone A: Pointing up    ‚Üë\n",
    "Bone B: Pointing up    ‚Üë  (rotated to match A)\n",
    "Bone C: Pointing up    ‚Üë  (rotated to match A)\n",
    "```\n",
    "Network learns pure shape variation!\n",
    "\n",
    "### üìä Dataset Size Considerations\n",
    "\n",
    "For this tutorial, we'll use **5 bones** to demonstrate concepts:\n",
    "- Large enough to show generative capabilities\n",
    "- Small enough for quick training and experimentation\n",
    "- Easily scalable to larger collections\n",
    "\n",
    "### üîç What to Watch For\n",
    "\n",
    "During loading, observe:\n",
    "- **Progress messages**: Tracking which bone is being processed\n",
    "- **Registration feedback**: How well bones align to reference\n",
    "- **Processing time**: Registration can be computationally intensive\n",
    "\n",
    "Let's build our multi-shape dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MULTI-SHAPE LOADING AND REGISTRATION: Build aligned bone collection\n",
    "# =============================================================================\n",
    "\n",
    "# Number of bones to load for generative modeling\n",
    "n = 5\n",
    "print(f\"ü¶¥ Loading and registering {n} tibia bones for generative training...\")\n",
    "print(f\"üìä This will create a shape collection for learning bone variation patterns\")\n",
    "\n",
    "# Initialize collection to store all registered bones\n",
    "list_tibs = []\n",
    "\n",
    "# =============================================================================\n",
    "# ITERATIVE LOADING: Process each bone with registration to reference\n",
    "# =============================================================================\n",
    "\n",
    "for idx in range(n):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f'üîÑ Processing bone {idx+1}/{n}')\n",
    "    print(f\"üìÅ File: {mesh_list[idx]}\")\n",
    "    \n",
    "    # Handle different loading strategies for Colab vs local environments\n",
    "    if is_colab:\n",
    "        # COLAB: Download bone file from GitHub and load locally\n",
    "        base_url = \"https://raw.githubusercontent.com/gattia/ISB-2025-Shape-Modeling/main/data\"\n",
    "        mesh_filename = mesh_list[idx]\n",
    "        path_tib_bone_url = f\"{base_url}/{mesh_filename}\"\n",
    "        local_path = f\"/content/{mesh_filename}\"  # Temporary local storage\n",
    "        \n",
    "        print(f\"üåê Downloading: {path_tib_bone_url}\")\n",
    "        \n",
    "        # Download bone file to Colab's temporary storage\n",
    "        !wget {path_tib_bone_url} -O {local_path} -q\n",
    "        \n",
    "        # Load mesh using PyVista (simpler for downloaded files)\n",
    "        tibia_mesh = pv.read(local_path)\n",
    "        \n",
    "    else:\n",
    "        # LOCAL: Load directly from local data directory\n",
    "        path_tib_bone = os.path.join('data', mesh_list[idx])\n",
    "        \n",
    "        # Skip if file doesn't exist in local dataset\n",
    "        if not os.path.exists(path_tib_bone):\n",
    "            print(f\"‚ö†Ô∏è File not found locally: {path_tib_bone}\")\n",
    "            continue\n",
    "            \n",
    "        # Load using pymskt for advanced mesh operations\n",
    "        tibia_mesh = mskt.mesh.Mesh(path_tib_bone)\n",
    "\n",
    "    # =============================================================================\n",
    "    # REFERENCE BONE SETUP: First bone becomes template for registration\n",
    "    # =============================================================================\n",
    "    \n",
    "    if idx == 0:\n",
    "        print(\"üéØ Setting up reference bone (template for registration)\")\n",
    "        \n",
    "        # Convert to pymskt.Mesh for advanced operations\n",
    "        ref_tibia = mskt.mesh.Mesh(tibia_mesh)\n",
    "        \n",
    "        # Normalize to standard coordinate system\n",
    "        normalize_bone(ref_tibia)\n",
    "        print(f\"üìè Normalized reference bone to unit coordinate system\")\n",
    "        \n",
    "        # Add to collection (no registration needed for reference)\n",
    "        list_tibs.append(ref_tibia)\n",
    "        print('‚úÖ Reference bone established - no registration needed')\n",
    "        continue\n",
    "\n",
    "    # =============================================================================\n",
    "    # SUBSEQUENT BONES: Normalize and register to reference template\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"üîß Processing bone {idx+1} - normalizing and registering...\")\n",
    "    \n",
    "    # Convert to pymskt.Mesh for registration capabilities\n",
    "    tibia = mskt.mesh.Mesh(tibia_mesh)\n",
    "    \n",
    "    # Apply same normalization as reference bone\n",
    "    normalize_bone(tibia)\n",
    "    print(f\"üìè Normalized bone {idx+1} to unit coordinate system\")\n",
    "    \n",
    "    # Perform rigid registration to align with reference bone\n",
    "    # This finds the best rotation + translation to match reference shape\n",
    "    print(f\"üéØ Registering bone {idx+1} to reference template...\")\n",
    "    tibia.rigidly_register(ref_tibia, return_transformed_mesh=True)\n",
    "    print(f\"‚úÖ Registration complete for bone {idx+1}\")\n",
    "    \n",
    "    # Add registered bone to collection\n",
    "    list_tibs.append(tibia)\n",
    "\n",
    "# =============================================================================\n",
    "# COLLECTION SUMMARY: Report final dataset statistics\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üéâ BONE COLLECTION COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìä Total bones loaded: {len(list_tibs)}\")\n",
    "print(f\"üéØ Reference bone: {mesh_list[0]}\")\n",
    "print(f\"üîÑ Registered bones: {len(list_tibs)-1}\")\n",
    "print(f\"‚úÖ All bones normalized and aligned to consistent coordinate system\")\n",
    "print(f\"üß† Ready for generative SDF training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3ea09c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Multi-Shape SDF Data Generation\n",
    "\n",
    "### üîÑ From Single-Shape to Multi-Shape Training Data\n",
    "\n",
    "**Tutorial #1**: Generated noisy points around one bone slice  \n",
    "**Tutorial #2**: Generate noisy points around multiple bone slices\n",
    "\n",
    "### üéØ Generative Training Data Strategy\n",
    "\n",
    "For each bone in our collection, we need to:\n",
    "1. **Create 2D slice** through the registered bone\n",
    "2. **Sample training points** around the slice boundary  \n",
    "3. **Compute ground truth SDFs** for each point\n",
    "4. **Associate bone identity** with each training sample\n",
    "\n",
    "### üß† Why Multi-Shape Data Generation?\n",
    "\n",
    "**Shared Spatial Learning**:\n",
    "- All bones occupy same coordinate region after registration\n",
    "- Network learns common tibia anatomy patterns\n",
    "- Individual bone differences captured via latent codes\n",
    "\n",
    "**Balanced Training**:\n",
    "- Equal sampling from each bone prevents bias toward any shape\n",
    "- Network sees diverse shape variations in each batch\n",
    "- Better generalization to unseen bone variations\n",
    "\n",
    "### üìä Training Data Structure\n",
    "\n",
    "```python\n",
    "For each bone_i in collection:\n",
    "    slice_i = bone_i.slice('y')\n",
    "    points_i, sdf_i = generate_sdf_points(slice_i)\n",
    "    \n",
    "Training batch = {\n",
    "    'coordinates': [points_1, points_2, ..., points_n],\n",
    "    'sdf_values': [sdf_1, sdf_2, ..., sdf_n], \n",
    "    'bone_ids': [0, 1, ..., n-1],  # Which bone each sample came from\n",
    "    'latent_codes': [z_0, z_1, ..., z_{n-1}]  # Learnable shape embeddings\n",
    "}\n",
    "```\n",
    "\n",
    "### üéõÔ∏è Data Generation Parameters\n",
    "\n",
    "Our function maintains the same sampling strategy as Tutorial #1:\n",
    "- **Close noise** (œÉ=0.01): High-precision surface boundary learning\n",
    "- **Far noise** (œÉ=0.075): Inside/outside classification and distance gradients\n",
    "- **Point count**: 20K points per bone for sufficient sampling density\n",
    "\n",
    "### üí´ The Key Innovation: Shape-Aware Sampling\n",
    "\n",
    "Unlike Tutorial #1 where we had global points and SDF values, now we have:\n",
    "- **Shape-specific points**: Each point knows which bone it came from\n",
    "- **Learnable latent codes**: Network learns unique embedding for each bone\n",
    "- **Shared coordinate space**: All points use same spatial coordinate system\n",
    "\n",
    "This enables the network to learn: `f(x, z, latent_bone_id) ‚Üí SDF`\n",
    "\n",
    "Let's implement our multi-shape data generation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1dc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# SDF POINT GENERATION FUNCTION: Create training data for generative modeling\n",
    "# =============================================================================\n",
    "\n",
    "def generate_sdf_points_on_slice(\n",
    "    mesh, \n",
    "    N=20_000, \n",
    "    close_sd=0.01, \n",
    "    far_sd=0.075, \n",
    "    slice_axis='y', \n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate noisy training points around a bone slice with ground truth SDF values.\n",
    "    \n",
    "    This function creates the training data needed for generative SDF learning\n",
    "    by sampling points around bone surfaces and computing their signed distances.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mesh : mskt.mesh.Mesh or pyvista.PolyData\n",
    "        The (already normalized and registered) bone mesh to process\n",
    "    N : int, default=20_000\n",
    "        Number of points per noise distribution (total = 2*N points)\n",
    "    close_sd : float, default=0.01\n",
    "        Standard deviation for near-surface point sampling\n",
    "        - Smaller values ‚Üí points closer to surface ‚Üí better boundary precision\n",
    "    far_sd : float, default=0.075  \n",
    "        Standard deviation for far-surface point sampling\n",
    "        - Larger values ‚Üí points further from surface ‚Üí better inside/outside learning\n",
    "    slice_axis : str, default='y'\n",
    "        Axis to slice along ('x', 'y', or 'z') - reduces 3D problem to 2D\n",
    "    verbose : bool, default=True\n",
    "        Whether to print progress messages during generation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    slice_ : pyvista.PolyData\n",
    "        The 2D slice extracted from the input mesh\n",
    "    pts_ : pyvista.PolyData\n",
    "        Generated training points with ground truth SDF values stored in \n",
    "        the 'implicit_distance' array\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Training point generation strategy:\n",
    "    1. Create 2D slice through bone (reduces computational complexity)\n",
    "    2. Sample N points with small noise ‚Üí near-surface training data\n",
    "    3. Sample N points with large noise ‚Üí far-surface training data  \n",
    "    4. Compute exact SDF values for all points using mesh geometry\n",
    "    \n",
    "    This provides balanced training data for both surface precision\n",
    "    and spatial understanding across the coordinate domain.\n",
    "    \"\"\"\n",
    "    \n",
    "    # =============================================================================\n",
    "    # SLICE EXTRACTION: Reduce 3D bone to 2D cross-section\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Create 2D slice through the bone at y‚âà0 (after registration)\n",
    "    # This simplifies the learning problem while maintaining anatomical structure\n",
    "    slice_ = mesh.slice(slice_axis)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"üìè Created slice with {slice_.n_points:,} boundary points\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # POINT SAMPLING: Generate diverse training coordinates\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Initialize array for all training points (2 distributions √ó N points each)\n",
    "    pts = np.zeros((N*2, 3))\n",
    "    \n",
    "    # Generate two different noise distributions for comprehensive training\n",
    "    for i, SD in enumerate([close_sd, far_sd]):\n",
    "        distribution_name = \"near-surface\" if i == 0 else \"far-surface\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üé≤ Generating {N:,} {distribution_name} points (œÉ={SD})\")\n",
    "        \n",
    "        # STEP 1: Randomly select seed points on the slice boundary\n",
    "        # These serve as starting locations for noise perturbation\n",
    "        indices = (np.random.sample(N) * slice_.points.shape[0]).astype(int)\n",
    "        \n",
    "        # STEP 2: Generate Gaussian noise for coordinate perturbation\n",
    "        # This creates points both inside (negative SDF) and outside (positive SDF)\n",
    "        x_noise = np.random.normal(loc=0, scale=SD, size=N)\n",
    "        z_noise = np.random.normal(loc=0, scale=SD, size=N)\n",
    "        \n",
    "        # STEP 3: Apply noise to create diverse point distribution\n",
    "        pts[i*N:(i+1)*N, 0] = slice_.points[indices, 0] + x_noise  # X coordinate\n",
    "        pts[i*N:(i+1)*N, 2] = slice_.points[indices, 2] + z_noise  # Z coordinate\n",
    "        # Y coordinate stays 0 (slice level) - will be handled by network input\n",
    "\n",
    "    # =============================================================================\n",
    "    # SDF COMPUTATION: Calculate ground truth signed distances\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Convert points to PyVista format for SDF computation\n",
    "    pts_ = pv.PolyData(pts)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"üìä Computing ground truth SDF values for {pts.shape[0]:,} points...\")\n",
    "    \n",
    "    # Compute signed distance from each point to the original mesh surface\n",
    "    # This gives us the target values our neural network will learn to predict\n",
    "    pts_.compute_implicit_distance(mesh, inplace=True)\n",
    "    \n",
    "    if verbose:\n",
    "        sdf_values = pts_['implicit_distance']\n",
    "        print(f\"‚úÖ SDF computation complete\")\n",
    "        print(f\"   ‚Ä¢ SDF range: [{sdf_values.min():.4f}, {sdf_values.max():.4f}]\")\n",
    "        print(f\"   ‚Ä¢ Points inside (SDF < 0): {(sdf_values < 0).sum():,}\")\n",
    "        print(f\"   ‚Ä¢ Points outside (SDF > 0): {(sdf_values > 0).sum():,}\")\n",
    "    \n",
    "    return slice_, pts_\n",
    "\n",
    "# =============================================================================\n",
    "# DEMONSTRATION: Generate training data for reference bone\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ Demonstrating SDF point generation on reference bone...\")\n",
    "print(\"This shows the training data creation process we'll apply to all bones\")\n",
    "\n",
    "# Generate example training data using the reference bone\n",
    "slice_, pts_ = generate_sdf_points_on_slice(\n",
    "    ref_tibia, \n",
    "    N=20_000, \n",
    "    close_sd=0.01, \n",
    "    far_sd=0.075,\n",
    "    slice_axis='y'\n",
    ")\n",
    "\n",
    "print(f\"\\nüé® Visualizing generated training data:\")\n",
    "print(f\"   ‚Ä¢ Blue/Purple points: Inside bone (negative SDF)\")  \n",
    "print(f\"   ‚Ä¢ Yellow/Red points: Outside bone (positive SDF)\")\n",
    "print(f\"   ‚Ä¢ Points near slice boundary: Critical for surface learning\")\n",
    "\n",
    "# Visualize the slice, full bone, and generated training points\n",
    "view(geometries=[slice_, ref_tibia], point_sets=pts_, point_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684b076",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Generative Neural Network Architecture\n",
    "\n",
    "### üöÄ From Single-Shape to Multi-Shape Networks\n",
    "\n",
    "**Tutorial #1 Architecture**:\n",
    "```\n",
    "f(x, z) ‚Üí SDF\n",
    "Input: 2D coordinates\n",
    "Output: Signed distance for ONE specific bone\n",
    "```\n",
    "\n",
    "**Tutorial #2 Architecture**:\n",
    "```\n",
    "f(x, z, latent_code) ‚Üí SDF  \n",
    "Input: 2D coordinates + shape embedding\n",
    "Output: Signed distance for ANY bone in our collection\n",
    "```\n",
    "\n",
    "### üß¨ Key Innovation: Latent Shape Embeddings\n",
    "\n",
    "**The Challenge**: How can one network represent multiple different bones?\n",
    "\n",
    "**The Solution**: **Latent Codes** - learnable vector embeddings that encode shape identity\n",
    "\n",
    "```python\n",
    "# Each bone gets a unique learnable vector\n",
    "bone_0: [0.1, -0.3, 0.7, 0.2, ...]  # 32-dimensional embedding\n",
    "bone_1: [0.4, 0.1, -0.2, 0.8, ...]  # Different embedding\n",
    "bone_2: [-0.2, 0.6, 0.3, -0.1, ...]  # Yet another embedding\n",
    "\n",
    "# Network learns: coordinates + bone_embedding ‚Üí SDF\n",
    "network(x=0.5, z=0.3, latent=bone_0_embedding) ‚Üí SDF for bone 0\n",
    "network(x=0.5, z=0.3, latent=bone_1_embedding) ‚Üí SDF for bone 1\n",
    "```\n",
    "\n",
    "### üéØ Architecture Components\n",
    "\n",
    "**1. Latent Embedding Layer**\n",
    "- `torch.nn.Embedding(num_bones, latent_dim)`\n",
    "- Creates learnable vector for each bone in our collection\n",
    "- Vectors start random, optimize during training to capture shape differences\n",
    "\n",
    "**2. Enhanced MLP Architecture**\n",
    "```\n",
    "Input: [x, z, latent_vector] ‚Üí Concatenated features\n",
    "Hidden Layer 1: 64 neurons + ReLU\n",
    "Hidden Layer 2: 64 neurons + ReLU  \n",
    "Output: Single SDF value\n",
    "```\n",
    "\n",
    "**3. Multi-Shape Dataset**\n",
    "- Samples points from ALL bones during training\n",
    "- Each sample includes coordinate + bone_id\n",
    "- Network learns shared patterns + individual variations\n",
    "\n",
    "### üß† How Learning Works\n",
    "\n",
    "**During Training**:\n",
    "1. **Sample batch**: Mix of points from different bones\n",
    "2. **Lookup embedding**: Get latent vector for each bone_id\n",
    "3. **Concatenate features**: [x, z, latent_vector] \n",
    "4. **Predict SDF**: Network outputs signed distance\n",
    "5. **Update weights**: Both MLP weights AND latent embeddings improve\n",
    "\n",
    "**What Network Learns**:\n",
    "- **Shared patterns**: Common tibia anatomy (all bones have similar structure)\n",
    "- **Individual variations**: Unique shape characteristics per bone\n",
    "- **Smooth interpolation**: Gradual transitions between bone types\n",
    "\n",
    "### üé® Generative Capabilities\n",
    "\n",
    "Once trained, we can:\n",
    "\n",
    "**1. Reconstruct Known Bones**\n",
    "```python\n",
    "bone_id = 2\n",
    "latent = embedding_layer(bone_id)\n",
    "sdf = network(coordinates, latent)  # Recreate bone 2\n",
    "```\n",
    "\n",
    "**2. Interpolate Between Bones**  \n",
    "```python\n",
    "latent_A = embedding_layer(bone_A)\n",
    "latent_B = embedding_layer(bone_B)\n",
    "latent_interp = 0.7 * latent_A + 0.3 * latent_B  # 70% A, 30% B\n",
    "sdf = network(coordinates, latent_interp)  # New hybrid bone!\n",
    "```\n",
    "\n",
    "**3. Generate Novel Bones**\n",
    "```python\n",
    "latent_new = sample_from_latent_distribution()  # Random vector\n",
    "sdf = network(coordinates, latent_new)  # Entirely new bone variation\n",
    "```\n",
    "\n",
    "### ‚öôÔ∏è Training Configuration\n",
    "\n",
    "**Key Parameters**:\n",
    "- `latent_dim = 32`: Size of shape embedding vectors\n",
    "- `batch_size = 2`: Number of bones per training batch  \n",
    "- `n_samples = 500`: Points sampled per bone per batch\n",
    "- `epochs = 40,000`: Extended training for generative learning\n",
    "\n",
    "**Loss Function**:\n",
    "```python\n",
    "loss = L1_loss(predicted_sdf, true_sdf) + regularization(latent_embeddings)\n",
    "```\n",
    "\n",
    "**Why Regularization?**: Prevents latent codes from growing too large, encourages smooth shape space\n",
    "\n",
    "Let's build our generative shape model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e233fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATIVE NEURAL NETWORK ARCHITECTURE: Multi-shape SDF learning\n",
    "# =============================================================================\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced Multi-Layer Perceptron for generative SDF learning.\n",
    "    \n",
    "    Key difference from Tutorial #1: This network accepts both spatial coordinates\n",
    "    AND latent shape embeddings, enabling it to represent multiple bone shapes.\n",
    "    \n",
    "    Architecture: [coordinates + latent] ‚Üí hidden ‚Üí hidden ‚Üí SDF\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=2, latent_dim=32, hidden_dim=64, output_dim=1):\n",
    "        \"\"\"\n",
    "        Initialize generative SDF network.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int, default=2\n",
    "            Spatial coordinate dimensions (x, z for 2D slice)\n",
    "        latent_dim : int, default=32\n",
    "            Size of latent shape embedding vectors\n",
    "        hidden_dim : int, default=64  \n",
    "            Number of neurons in hidden layers\n",
    "        output_dim : int, default=1\n",
    "            Output dimensions (1 for signed distance)\n",
    "        \"\"\"\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Network concatenates spatial coordinates with shape embedding\n",
    "        total_input_dim = input_dim + latent_dim\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # First hidden layer: Process combined spatial + shape features\n",
    "            nn.Linear(total_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Second hidden layer: Refine feature representations\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Output layer: Single SDF prediction\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, latent):\n",
    "        \"\"\"\n",
    "        Forward pass: Predict SDF from coordinates and shape embedding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor, shape (batch_size, input_dim)\n",
    "            Spatial coordinates (e.g., x, z positions)\n",
    "        latent : torch.Tensor, shape (batch_size, latent_dim)\n",
    "            Shape embedding vectors for each sample\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor, shape (batch_size, 1)\n",
    "            Predicted signed distance values\n",
    "        \"\"\"\n",
    "        # Concatenate spatial coordinates with shape embeddings\n",
    "        x_cat = torch.cat([x, latent], dim=-1)\n",
    "        \n",
    "        # Process through MLP to predict SDF\n",
    "        return self.net(x_cat)\n",
    "\n",
    "# =============================================================================\n",
    "# MULTI-SHAPE DATASET: Training data for generative learning\n",
    "# =============================================================================\n",
    "\n",
    "class PointsSDFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for multi-shape generative SDF training.\n",
    "    \n",
    "    Key innovation: Generates training data from multiple bone shapes\n",
    "    and associates each sample with its source bone identity.\n",
    "    \"\"\"\n",
    "    def __init__(self, mesh_list, n_sample=500, N=20_000, close_sd=0.01, \n",
    "                 far_sd=0.075, max_sdf=0.1, slice_axis='y', verbose=False):\n",
    "        \"\"\"\n",
    "        Initialize multi-shape training dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        mesh_list : list of mskt.mesh.Mesh\n",
    "            Collection of registered bone meshes\n",
    "        n_sample : int, default=500\n",
    "            Number of points to sample per bone per training batch\n",
    "        N : int, default=20_000\n",
    "            Total points generated per bone (2*N due to two noise levels)\n",
    "        close_sd : float, default=0.01\n",
    "            Standard deviation for near-surface point sampling\n",
    "        far_sd : float, default=0.075\n",
    "            Standard deviation for far-surface point sampling  \n",
    "        max_sdf : float, default=0.1\n",
    "            Clamp SDF values to focus learning on surface proximity\n",
    "        slice_axis : str, default='y'\n",
    "            Axis for 2D slice extraction\n",
    "        verbose : bool, default=False\n",
    "            Print progress during data generation\n",
    "        \"\"\"\n",
    "        print(f\"üèóÔ∏è Building multi-shape dataset from {len(mesh_list)} bones...\")\n",
    "        \n",
    "        self.xz = []        # Spatial coordinates for each bone\n",
    "        self.sdf = []       # SDF values for each bone  \n",
    "        self.n_sample = n_sample\n",
    "        \n",
    "        # Generate training data for each bone in the collection\n",
    "        for i, mesh in enumerate(mesh_list):\n",
    "            if verbose:\n",
    "                print(f\"   Processing bone {i+1}/{len(mesh_list)}\")\n",
    "                \n",
    "            # Generate SDF training points using our established function\n",
    "            _, pts_ = generate_sdf_points_on_slice(\n",
    "                mesh, N=N, close_sd=close_sd, far_sd=far_sd, \n",
    "                slice_axis=slice_axis, verbose=verbose\n",
    "            )\n",
    "            \n",
    "            # Extract coordinate data (x, z) - ignore y since we're using slices\n",
    "            pts = pts_.points  # Shape: (2*N, 3)\n",
    "            sdf = pts_['implicit_distance']  # Shape: (2*N,)\n",
    "            \n",
    "            # Convert to PyTorch tensors\n",
    "            xz_tensor = torch.tensor(pts[:, [0, 2]], dtype=torch.float32)\n",
    "            sdf_tensor = torch.tensor(sdf, dtype=torch.float32).unsqueeze(1)\n",
    "            \n",
    "            # Clamp SDF values to focus learning on surface region\n",
    "            sdf_tensor = torch.clamp(sdf_tensor, min=-max_sdf, max=max_sdf)\n",
    "            \n",
    "            # Store bone-specific training data\n",
    "            self.xz.append(xz_tensor)\n",
    "            self.sdf.append(sdf_tensor)\n",
    "        \n",
    "        # Verify consistent data sizes across all bones\n",
    "        self.point_batch_size = self.xz[0].shape[0]\n",
    "        print(f\"‚úÖ Dataset ready: {len(mesh_list)} bones √ó {self.point_batch_size:,} points each\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return number of bones in dataset.\"\"\"\n",
    "        return len(self.xz)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Sample training data for the idx-th bone.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (bone_idx, coordinates, sdf_values)\n",
    "            - bone_idx: Which bone this data came from (for latent lookup)\n",
    "            - coordinates: Random sample of spatial positions  \n",
    "            - sdf_values: Corresponding ground truth signed distances\n",
    "        \"\"\"\n",
    "        # Randomly sample n_sample points from this bone's full dataset\n",
    "        N = self.xz[idx].shape[0]\n",
    "        indices = np.random.choice(N, size=self.n_sample, replace=False)\n",
    "        \n",
    "        return idx, self.xz[idx][indices], self.sdf[idx][indices]\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING CONFIGURATION: Setup for generative learning\n",
    "# =============================================================================\n",
    "\n",
    "print(\"‚öôÔ∏è Configuring generative SDF training...\")\n",
    "\n",
    "# Training hyperparameters - optimized for multi-shape learning\n",
    "num_epochs = 40_000      # Extended training for generative models\n",
    "n_samples = 500          # Points sampled per bone per batch\n",
    "batch_size = 2           # Number of different bones per training batch\n",
    "latent_dim = 32          # Dimensionality of shape embeddings\n",
    "latent_init_std = 0.1    # Initial scale of latent vectors\n",
    "slice_axis = 'y'         # Slice direction for 2D learning\n",
    "\n",
    "print(f\"üìä Training configuration:\")\n",
    "print(f\"   ‚Ä¢ Epochs: {num_epochs:,}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {batch_size} bones\")  \n",
    "print(f\"   ‚Ä¢ Points per bone: {n_samples}\")\n",
    "print(f\"   ‚Ä¢ Latent dimensions: {latent_dim}\")\n",
    "\n",
    "# =============================================================================\n",
    "# LATENT EMBEDDING LAYER: Learnable shape codes\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üß¨ Initializing latent embeddings for {len(list_tibs)} bones...\")\n",
    "\n",
    "# Create embedding layer: each bone gets a learnable latent vector\n",
    "lat_vecs = torch.nn.Embedding(\n",
    "    num_embeddings=len(list_tibs),  # One embedding per bone\n",
    "    embedding_dim=latent_dim,       # 32-dimensional shape codes\n",
    "    max_norm=10.0                   # Prevent embeddings from growing too large\n",
    ")\n",
    "\n",
    "# Initialize embeddings with small random values\n",
    "# This ensures training starts from a reasonable state\n",
    "torch.nn.init.normal_(\n",
    "    lat_vecs.weight.data,\n",
    "    mean=0.0,\n",
    "    std=latent_init_std / math.sqrt(latent_dim),  # Scaled initialization\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Latent embeddings initialized: {len(list_tibs)} √ó {latent_dim}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET AND MODEL INITIALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üèóÔ∏è Building training pipeline...\")\n",
    "\n",
    "# Create multi-shape dataset\n",
    "dataset = PointsSDFDataset(\n",
    "    mesh_list=list_tibs, \n",
    "    n_sample=n_samples, \n",
    "    N=20_000,\n",
    "    close_sd=0.01, \n",
    "    far_sd=0.075,\n",
    "    max_sdf=0.1, \n",
    "    slice_axis=slice_axis,\n",
    "    verbose=False  # Set to True for detailed data generation logs\n",
    ")\n",
    "\n",
    "# Create data loader for efficient batch processing\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=batch_size,  # Process multiple bones per batch\n",
    "    shuffle=True            # Randomize bone order each epoch\n",
    ")\n",
    "\n",
    "# Initialize generative network\n",
    "model = SimpleMLP(\n",
    "    input_dim=2,           # 2D coordinates (x, z)\n",
    "    latent_dim=latent_dim, # Shape embedding size\n",
    "    hidden_dim=32,         # Network capacity\n",
    "    output_dim=1           # Single SDF output\n",
    ")\n",
    "\n",
    "# Setup optimization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()  # L1 loss for sharp surface reconstruction\n",
    "\n",
    "print(f\"üß† Network initialized:\")\n",
    "print(f\"   ‚Ä¢ Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   ‚Ä¢ Input: coordinates + {latent_dim}D latent ‚Üí SDF\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING LOOP: Learn generative SDF representation\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüöÄ Starting generative SDF training...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Process each batch (contains multiple bones)\n",
    "    for batch_idx, (bone_indices, xz_coords, sdf_targets) in enumerate(dataloader):\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # STEP 1: Lookup latent embeddings for bones in this batch\n",
    "        latents = lat_vecs(bone_indices)  # Shape: (batch_size, latent_dim)\n",
    "        \n",
    "        # STEP 2: Expand latents to match coordinate samples \n",
    "        # We need the same latent vector for all points from the same bone\n",
    "        latents = latents.unsqueeze(1).expand(-1, n_samples, -1)  # (batch, n_samples, latent_dim)\n",
    "        \n",
    "        # STEP 3: Predict SDF values using coordinates + shape embeddings\n",
    "        pred_sdf = model(xz_coords, latents)\n",
    "        \n",
    "        # STEP 4: Compute loss components\n",
    "        # SDF reconstruction loss - how well we predict signed distances\n",
    "        sdf_loss = criterion(pred_sdf, sdf_targets)\n",
    "        \n",
    "        # Latent regularization - prevent embeddings from growing too large\n",
    "        lat_loss = torch.sum(torch.norm(latents, dim=-1))\n",
    "        \n",
    "        # Combined loss: reconstruction + regularization\n",
    "        total_loss = sdf_loss + lat_loss\n",
    "        \n",
    "        # STEP 5: Backpropagation and parameter updates\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss statistics\n",
    "        running_loss += total_loss.item() * xz_coords.size(0)\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    \n",
    "    # Progress reporting\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1:5d}/{num_epochs:,} | Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üéâ Training complete!\")\n",
    "print(f\"‚úÖ Network learned to represent {len(list_tibs)} bone shapes\")\n",
    "print(f\"üéØ Ready for generative modeling and shape interpolation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22745a4e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: Evaluating the Generative Model\n",
    "\n",
    "### üéØ From Training to Generation\n",
    "\n",
    "Congratulations! Your generative SDF model is now trained. Unlike Tutorial #1 where we learned one specific bone, we now have a model that can:\n",
    "\n",
    "1. **Reconstruct any of the 5 training bones**\n",
    "2. **Interpolate between different bone shapes**  \n",
    "3. **Generate entirely new bone variations**\n",
    "\n",
    "### üé® Visualization Strategy\n",
    "\n",
    "We'll evaluate our model by:\n",
    "\n",
    "**Grid-Based SDF Evaluation**:\n",
    "- Create dense 2D grid of query points\n",
    "- For a specific bone, lookup its latent embedding\n",
    "- Predict SDF values across the entire grid\n",
    "- Visualize the learned SDF field\n",
    "\n",
    "**Surface Reconstruction**:\n",
    "- Use marching cubes to extract zero level set\n",
    "- Compare reconstructed surface to original bone\n",
    "- Assess geometric accuracy and smoothness\n",
    "\n",
    "### üîß Model Evaluation Process\n",
    "\n",
    "```python\n",
    "# STEP 1: Choose which bone to reconstruct\n",
    "LATENT_IDX = 0  # Bone index (0 to 4 in our case)\n",
    "\n",
    "# STEP 2: Get the learned latent embedding for this bone  \n",
    "latent_code = embedding_layer(LATENT_IDX)\n",
    "\n",
    "# STEP 3: Create grid of query coordinates\n",
    "grid_coordinates = create_coordinate_grid()\n",
    "\n",
    "# STEP 4: Predict SDF values using coordinates + latent code\n",
    "sdf_predictions = model(grid_coordinates, latent_code)\n",
    "\n",
    "# STEP 5: Visualize and reconstruct\n",
    "visualize_sdf_field(sdf_predictions)\n",
    "reconstruct_surface(sdf_predictions)\n",
    "```\n",
    "\n",
    "### üéõÔ∏è Key Parameters\n",
    "\n",
    "**Grid Resolution**: Controls detail level of reconstruction\n",
    "- Higher resolution ‚Üí more detailed surfaces, slower computation\n",
    "- Lower resolution ‚Üí faster computation, less detail\n",
    "\n",
    "**Latent Index**: Which bone to reconstruct\n",
    "- `LATENT_IDX = 0` ‚Üí First bone (reference)\n",
    "- `LATENT_IDX = 1` ‚Üí Second bone  \n",
    "- etc.\n",
    "\n",
    "### üöÄ What to Look For\n",
    "\n",
    "**Successful Learning Indicators**:\n",
    "- SDF field smoothly transitions from negative (inside) to positive (outside)\n",
    "- Zero level set closely matches original bone shape\n",
    "- Different latent codes produce different bone geometries\n",
    "- No artifacts or discontinuities in the SDF field\n",
    "\n",
    "**Quality Assessment**:\n",
    "- **Geometric accuracy**: How well does reconstruction match original?\n",
    "- **Surface smoothness**: Are there any jagged artifacts?\n",
    "- **Shape diversity**: Do different bones look appropriately different?\n",
    "\n",
    "Let's evaluate our trained generative model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SDF FIELD VISUALIZATION: Evaluate learned generative representation\n",
    "# =============================================================================\n",
    "\n",
    "# Choose which bone to reconstruct (0 to 4 for our 5-bone dataset)\n",
    "LATENT_IDX = 0\n",
    "print(f\"üéØ Evaluating generative model for bone {LATENT_IDX}\")\n",
    "print(f\"üìÅ Reconstructing: {mesh_list[LATENT_IDX]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# GRID GENERATION: Create dense coordinate sampling for SDF evaluation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìê Generating evaluation grid...\")\n",
    "\n",
    "# Create high-resolution coordinate grid for detailed SDF field visualization\n",
    "GRID_STEP = 0.01  # Grid resolution (smaller = more detailed, slower)\n",
    "x = np.arange(-1, 1.01, GRID_STEP)\n",
    "z = np.arange(-1, 1.01, GRID_STEP)\n",
    "\n",
    "print(f\"   ‚Ä¢ Grid resolution: {len(x)} √ó {len(z)} = {len(x) * len(z):,} query points\")\n",
    "print(f\"   ‚Ä¢ Coordinate range: [{x.min()}, {x.max()}] √ó [{z.min()}, {z.max()}]\")\n",
    "\n",
    "# Create coordinate meshgrid and flatten for network evaluation\n",
    "xx, zz = np.meshgrid(x, z)\n",
    "xz_grid = np.stack([xx.ravel(), zz.ravel()], axis=1)\n",
    "\n",
    "# Convert to PyTorch tensor for model inference  \n",
    "xz_tensor = torch.from_numpy(xz_grid).float()\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATIVE SDF PREDICTION: Query network with specific latent code\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üß† Predicting SDF field using learned latent embedding...\")\n",
    "\n",
    "# Disable gradient computation for inference (faster, less memory)\n",
    "with torch.no_grad():\n",
    "    # STEP 1: Lookup learned latent embedding for the specified bone\n",
    "    latent = lat_vecs(torch.tensor(LATENT_IDX))\n",
    "    print(f\"   ‚Ä¢ Latent vector shape: {latent.shape}\")\n",
    "    print(f\"   ‚Ä¢ Latent vector norm: {torch.norm(latent).item():.3f}\")\n",
    "    \n",
    "    # STEP 2: Expand latent to match number of query points\n",
    "    # Each coordinate gets the same latent code (identifies the bone shape)\n",
    "    latent_expanded = latent.expand(xz_tensor.size(0), -1)\n",
    "    print(f\"   ‚Ä¢ Expanded latent shape: {latent_expanded.shape}\")\n",
    "    \n",
    "    # STEP 3: Predict SDF values across the entire grid\n",
    "    sdf_pred = model(xz_tensor, latent_expanded).cpu().numpy().flatten()\n",
    "\n",
    "print(f\"‚úÖ SDF field prediction complete\")\n",
    "print(f\"   ‚Ä¢ SDF range: [{sdf_pred.min():.4f}, {sdf_pred.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Points inside (SDF < 0): {(sdf_pred < 0).sum():,}\")\n",
    "print(f\"   ‚Ä¢ Points outside (SDF > 0): {(sdf_pred > 0).sum():,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION PREPARATION: Convert predictions to 3D point cloud\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üé® Preparing SDF field visualization...\")\n",
    "\n",
    "# Convert 2D grid coordinates to 3D points (x, 0, z) for visualization\n",
    "# Y = 0 since we're working with a slice through the bone\n",
    "xyz_coords = np.stack([\n",
    "    xz_grid[:, 0],                    # X coordinates  \n",
    "    np.zeros_like(xz_grid[:, 0]),     # Y = 0 (slice level)\n",
    "    xz_grid[:, 1]                     # Z coordinates\n",
    "], axis=1)\n",
    "\n",
    "# Create PyVista point cloud for interactive visualization\n",
    "xyz_points = pv.PolyData(xyz_coords)\n",
    "\n",
    "# Assign predicted SDF values as point data for color mapping\n",
    "xyz_points['Predicted_SDF'] = sdf_pred\n",
    "\n",
    "# =============================================================================\n",
    "# INTERACTIVE VISUALIZATION: Compare learned vs. original bone\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üìä Visualizing learned SDF field for bone {LATENT_IDX}...\")\n",
    "print(f\"üé® Color interpretation:\")\n",
    "print(f\"   ‚Ä¢ Blue/Purple: Inside bone (negative SDF)\")\n",
    "print(f\"   ‚Ä¢ Yellow/Red: Outside bone (positive SDF)\")\n",
    "print(f\"   ‚Ä¢ Green: Near surface (SDF ‚âà 0)\")\n",
    "\n",
    "# Get original slice for comparison\n",
    "original_slice = list_tibs[LATENT_IDX].slice('y')\n",
    "\n",
    "print(f\"\\nüîç Visual comparison:\")\n",
    "print(f\"   ‚Ä¢ Wireframe: Original bone slice\")\n",
    "print(f\"   ‚Ä¢ Solid mesh: Original full bone\")  \n",
    "print(f\"   ‚Ä¢ Colored points: Learned SDF field\")\n",
    "\n",
    "# Create interactive 3D visualization comparing:\n",
    "# 1. Original bone slice (wireframe)\n",
    "# 2. Original full bone (solid)\n",
    "# 3. Learned SDF field (colored points)\n",
    "view(\n",
    "    geometries=[original_slice, list_tibs[LATENT_IDX]], \n",
    "    point_sets=xyz_points, \n",
    "    point_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce66cd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7: Generative Surface Reconstruction\n",
    "\n",
    "### üéØ From SDF Field to 3D Surface\n",
    "\n",
    "The previous visualization showed us the raw SDF field as colored points. Now we'll extract the actual bone surface using marching cubes - but with a generative twist!\n",
    "\n",
    "### üîÑ Generative vs. Traditional Reconstruction\n",
    "\n",
    "**Traditional Reconstruction** (Tutorial #1):\n",
    "- Fixed surface for one specific bone\n",
    "- Reconstruct the single learned shape\n",
    "\n",
    "**Generative Reconstruction** (Tutorial #2):\n",
    "- **Any bone in our collection**: Change `LATENT_IDX` to reconstruct different bones\n",
    "- **Interpolated shapes**: Blend latent codes to create hybrid bones\n",
    "- **Novel variations**: Sample new latent codes for entirely new bones\n",
    "\n",
    "### üé® Reconstruction Process\n",
    "\n",
    "**Our Approach**:\n",
    "1. **Setup 3D grid** for marching cubes algorithm\n",
    "2. **Choose target bone** via latent index\n",
    "3. **Predict SDF field** using coordinates + latent embedding\n",
    "4. **Extract zero level set** where SDF transitions from negative to positive\n",
    "5. **Compare reconstruction** with original bone geometry\n",
    "\n",
    "### üß™ Experimental Possibilities\n",
    "\n",
    "Once you understand this process, try:\n",
    "\n",
    "**Explore Different Bones**:\n",
    "```python\n",
    "LATENT_IDX = 0  # First bone\n",
    "LATENT_IDX = 1  # Second bone  \n",
    "LATENT_IDX = 2  # Third bone\n",
    "# etc.\n",
    "```\n",
    "\n",
    "**Shape Interpolation** (advanced):\n",
    "```python\n",
    "latent_A = lat_vecs(torch.tensor(0))  # First bone\n",
    "latent_B = lat_vecs(torch.tensor(1))  # Second bone\n",
    "latent_interp = 0.5 * latent_A + 0.5 * latent_B  # 50/50 blend\n",
    "# Use latent_interp for reconstruction ‚Üí hybrid bone!\n",
    "```\n",
    "\n",
    "**Novel Shape Generation** (advanced):\n",
    "```python\n",
    "latent_new = torch.randn(latent_dim) * 0.1  # Random latent code\n",
    "# Use latent_new for reconstruction ‚Üí entirely new bone variation!\n",
    "```\n",
    "\n",
    "### üéØ Quality Assessment\n",
    "\n",
    "**What to Look For**:\n",
    "- **Surface smoothness**: Clean, artifact-free reconstruction\n",
    "- **Anatomical accuracy**: Preserved bone structure and proportions\n",
    "- **Shape diversity**: Different bones should look appropriately different\n",
    "- **Boundary precision**: Sharp transitions between inside/outside regions\n",
    "\n",
    "### üìä Reconstruction Parameters\n",
    "\n",
    "**Grid Resolution**: Balance between detail and computation time\n",
    "- `n = 100` ‚Üí Quick preview reconstruction  \n",
    "- `n = 200` ‚Üí High-detail reconstruction (slower)\n",
    "\n",
    "**Spatial Bounds**: Ensure we cover the bone region\n",
    "- `[-1, 1]` range matches our normalized coordinate system\n",
    "\n",
    "Let's extract our generative bone surface!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f74d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATIVE SURFACE RECONSTRUCTION: Extract bone geometry from learned SDF\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üèóÔ∏è Reconstructing 3D surface for bone {LATENT_IDX} using generative model...\")\n",
    "\n",
    "# =============================================================================\n",
    "# MARCHING CUBES GRID SETUP: Create structured 3D grid for surface extraction\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìê Setting up marching cubes grid...\")\n",
    "\n",
    "# Grid resolution for surface extraction (balance detail vs. computation)\n",
    "n = 100  # Grid points per dimension (higher = more detail, slower)\n",
    "\n",
    "# Spatial bounds matching our normalized coordinate system\n",
    "x_min, y_min, z_min = -1.0, -0.01, -1.0   # Minimum bounds\n",
    "x_max, y_max, z_max =  1.0,  0.01,  1.0    # Maximum bounds\n",
    "\n",
    "print(f\"   ‚Ä¢ Grid resolution: {n} √ó 2 √ó {n} = {n*2*n:,} total points\")\n",
    "print(f\"   ‚Ä¢ Spatial coverage: X[{x_min}, {x_max}], Y[{y_min}, {y_max}], Z[{z_min}, {z_max}]\")\n",
    "\n",
    "# Calculate grid spacing\n",
    "spacing = (\n",
    "    (x_max - x_min) / (n - 1),  # X direction spacing\n",
    "    0.01,                       # Y direction spacing (thin slice)\n",
    "    (z_max - z_min) / (n - 1),  # Z direction spacing\n",
    ")\n",
    "\n",
    "# Create structured grid for marching cubes algorithm\n",
    "grid = pv.ImageData(\n",
    "    dimensions=(n, 2, n),     # Grid dimensions\n",
    "    spacing=spacing,          # Point spacing\n",
    "    origin=(x_min, y_min, z_min),  # Grid origin\n",
    ")\n",
    "\n",
    "# Extract grid coordinates for SDF evaluation\n",
    "x, y, z = grid.points.T\n",
    "\n",
    "print(f\"‚úÖ Grid created with {grid.n_points:,} evaluation points\")\n",
    "\n",
    "# =============================================================================\n",
    "# GENERATIVE SDF EVALUATION: Predict signed distances across the grid\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üß† Evaluating generative SDF field across reconstruction grid...\")\n",
    "\n",
    "# Prepare coordinate input for the neural network\n",
    "# Extract (x, z) coordinates since we're working with 2D slices\n",
    "xz_grid_3d = np.stack([x, z], axis=1)\n",
    "xz_tensor_3d = torch.from_numpy(xz_grid_3d).float()\n",
    "\n",
    "print(f\"   ‚Ä¢ Coordinate tensor shape: {xz_tensor_3d.shape}\")\n",
    "\n",
    "# Predict SDF values using the trained generative model\n",
    "with torch.no_grad():\n",
    "    # Get the learned latent embedding for the target bone\n",
    "    latent = lat_vecs(torch.tensor(LATENT_IDX))\n",
    "    print(f\"   ‚Ä¢ Using latent embedding: shape {latent.shape}, norm {torch.norm(latent).item():.3f}\")\n",
    "    \n",
    "    # Expand latent to match all grid points (same bone identity for all points)\n",
    "    latent_expanded = latent.expand(xz_tensor_3d.size(0), -1)\n",
    "    \n",
    "    # Generate SDF predictions across the entire grid\n",
    "    sdf_pred_3d = model(xz_tensor_3d, latent_expanded).cpu().numpy().flatten()\n",
    "\n",
    "print(f\"‚úÖ SDF evaluation complete\")\n",
    "print(f\"   ‚Ä¢ SDF range: [{sdf_pred_3d.min():.4f}, {sdf_pred_3d.max():.4f}]\")\n",
    "print(f\"   ‚Ä¢ Zero crossings: {((sdf_pred_3d[:-1] * sdf_pred_3d[1:]) < 0).sum():,} detected\")\n",
    "\n",
    "# =============================================================================\n",
    "# MARCHING CUBES: Extract zero level set as triangulated surface\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üî∫ Running marching cubes algorithm...\")\n",
    "\n",
    "# Extract isosurface where SDF = 0 (the bone boundary)\n",
    "# This creates a triangulated mesh representing the reconstructed bone surface\n",
    "reconstructed_mesh = grid.contour([0], sdf_pred_3d, method='marching_cubes')\n",
    "\n",
    "# Compute surface normals for proper lighting and visualization\n",
    "reconstructed_mesh.compute_normals(inplace=True)\n",
    "\n",
    "print(f\"‚úÖ Surface reconstruction complete\")\n",
    "print(f\"   ‚Ä¢ Vertices: {reconstructed_mesh.n_points:,}\")\n",
    "print(f\"   ‚Ä¢ Faces: {reconstructed_mesh.n_cells:,}\")\n",
    "print(f\"   ‚Ä¢ Surface area: {reconstructed_mesh.area:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# COMPARISON PREPARATION: Get original bone slice for reference\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Preparing comparison with original bone...\")\n",
    "\n",
    "# Extract slice from the original bone for visual comparison\n",
    "original_slice = list_tibs[LATENT_IDX].slice('y')\n",
    "\n",
    "print(f\"   ‚Ä¢ Original slice: {original_slice.n_points:,} points\")\n",
    "print(f\"   ‚Ä¢ Reconstruction: {reconstructed_mesh.n_points:,} points\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL VISUALIZATION: Compare reconstruction with original\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüé® Creating final comparison visualization...\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"GENERATIVE SURFACE RECONSTRUCTION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ü¶¥ Target bone: {mesh_list[LATENT_IDX]}\")\n",
    "print(f\"üéØ Latent index: {LATENT_IDX}\")\n",
    "print(f\"üîç Visual elements:\")\n",
    "print(f\"   ‚Ä¢ Colored surface: Generative reconstruction\")\n",
    "print(f\"   ‚Ä¢ Wireframe: Original bone slice\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nüí° Experiment suggestions:\")\n",
    "print(f\"   ‚Ä¢ Try different LATENT_IDX values (0-{len(list_tibs)-1}) to reconstruct other bones\")\n",
    "print(f\"   ‚Ä¢ Compare reconstruction quality across different bones\")\n",
    "print(f\"   ‚Ä¢ Observe how latent embeddings capture shape differences\")\n",
    "\n",
    "# Create interactive visualization comparing:\n",
    "# 1. Generative reconstruction (colored surface)\n",
    "# 2. Original bone slice (wireframe reference)\n",
    "view(geometries=[reconstructed_mesh, original_slice])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42321e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 8: Exploring the Shape Space - Mean Shape Generation\n",
    "\n",
    "### üéØ Beyond Individual Reconstruction\n",
    "\n",
    "So far, we've reconstructed specific bones using their individual latent codes. But our generative model enables something even more powerful: **shape space exploration**!\n",
    "\n",
    "### üß¨ The Concept of \"Average\" Shapes\n",
    "\n",
    "One of the most interesting properties of latent shape spaces is the ability to compute **canonical** or **average** shapes:\n",
    "\n",
    "```python\n",
    "# Individual bone shapes:\n",
    "bone_0 = f(coordinates, latent_vector_0)  # Patient A's specific anatomy\n",
    "bone_1 = f(coordinates, latent_vector_1)  # Patient B's specific anatomy\n",
    "\n",
    "# Average bone shape:\n",
    "mean_latent = (latent_vector_0 + latent_vector_1 + ...) / num_bones\n",
    "average_bone = f(coordinates, mean_latent)  # Population average anatomy!\n",
    "```\n",
    "\n",
    "### üî¨ Why Average Shapes Matter\n",
    "\n",
    "**Statistical Shape Analysis**:\n",
    "- **Population norms**: What does a \"typical\" tibia look like?\n",
    "- **Pathology detection**: How far is a patient's bone from the population average?\n",
    "- **Reference templates**: Standardized anatomy for medical education\n",
    "\n",
    "**Clinical Applications**:\n",
    "- **Surgical planning**: Start with average anatomy, then personalize\n",
    "- **Implant design**: Design for the population average, then customize\n",
    "- **Growth modeling**: Track how individual bones deviate from population means\n",
    "\n",
    "**Research Applications**:\n",
    "- **Shape variation studies**: Understanding anatomical diversity\n",
    "- **Developmental biology**: How shapes change with age/development\n",
    "- **Comparative anatomy**: Differences between populations or species\n",
    "\n",
    "\n",
    "\n",
    "Let's generate and visualize the population average tibia!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MEAN SHAPE GENERATION: Explore the center of our learned shape space\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üß¨ Generating population average tibia using mean latent embedding...\")\n",
    "print(\"This demonstrates latent space arithmetic and canonical shape generation\")\n",
    "\n",
    "# =============================================================================\n",
    "# LATENT SPACE ANALYSIS: Compute statistics of learned shape embeddings\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìä Analyzing learned latent space...\")\n",
    "\n",
    "# Extract all learned latent embeddings for analysis\n",
    "all_latents = lat_vecs.weight.data  # Shape: (num_bones, latent_dim)\n",
    "\n",
    "print(f\"   ‚Ä¢ Latent space dimensions: {all_latents.shape}\")\n",
    "print(f\"   ‚Ä¢ Number of bone embeddings: {all_latents.shape[0]}\")\n",
    "print(f\"   ‚Ä¢ Embedding vector size: {all_latents.shape[1]}\")\n",
    "\n",
    "# Compute latent space statistics\n",
    "latent_mean = all_latents.mean(dim=0, keepdim=True)  # Population center\n",
    "latent_std = all_latents.std(dim=0)                  # Per-dimension variation\n",
    "latent_range = all_latents.max(dim=0)[0] - all_latents.min(dim=0)[0]  # Value ranges\n",
    "\n",
    "print(f\"   ‚Ä¢ Mean latent norm: {torch.norm(latent_mean).item():.3f}\")\n",
    "print(f\"   ‚Ä¢ Average standard deviation: {latent_std.mean().item():.3f}\")\n",
    "print(f\"   ‚Ä¢ Average range: {latent_range.mean().item():.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# RECONSTRUCTION GRID SETUP: Same spatial domain as individual bones\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nüìê Setting up reconstruction grid for mean shape...\")\n",
    "\n",
    "# Use same grid parameters as individual bone reconstruction for comparison\n",
    "n = 100  # Grid resolution\n",
    "x_min, y_min, z_min = -1.0, -0.01, -1.0   # Spatial bounds\n",
    "x_max, y_max, z_max =  1.0,  0.01,  1.0\n",
    "\n",
    "print(f\"   ‚Ä¢ Grid resolution: {n} √ó 2 √ó {n} = {n*2*n:,} points\")\n",
    "\n",
    "# Create reconstruction grid\n",
    "spacing = (\n",
    "    (x_max - x_min) / (n - 1),  # X spacing\n",
    "    0.01,                       # Y spacing (thin slice)  \n",
    "    (z_max - z_min) / (n - 1),  # Z spacing\n",
    ")\n",
    "\n",
    "grid = pv.ImageData(\n",
    "    dimensions=(n, 2, n),\n",
    "    spacing=spacing,\n",
    "    origin=(x_min, y_min, z_min),\n",
    ")\n",
    "\n",
    "x, y, z = grid.points.T\n",
    "\n",
    "# =============================================================================\n",
    "# MEAN SHAPE SDF GENERATION: Use population average latent code\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üéØ Generating SDF field using mean latent embedding...\")\n",
    "\n",
    "# Prepare spatial coordinates for network evaluation\n",
    "xz_grid_3d = np.stack([x, z], axis=1)\n",
    "xz_tensor_3d = torch.from_numpy(xz_grid_3d).float()\n",
    "\n",
    "print(f\"   ‚Ä¢ Coordinate tensor shape: {xz_tensor_3d.shape}\")\n",
    "\n",
    "# Generate SDF predictions using the MEAN of all learned latent embeddings\n",
    "with torch.no_grad():\n",
    "    # CRITICAL: Use mean of all latent vectors ‚Üí \"average\" bone shape\n",
    "    # This represents the center point of our learned shape space\n",
    "    latent_mean = lat_vecs.weight.mean(dim=0, keepdim=True)\n",
    "    print(f\"   ‚Ä¢ Mean latent shape: {latent_mean.shape}\")\n",
    "    print(f\"   ‚Ä¢ Mean latent norm: {torch.norm(latent_mean).item():.3f}\")\n",
    "    \n",
    "    # Expand mean latent to match all grid points\n",
    "    latent_expanded = latent_mean.expand(xz_tensor_3d.size(0), -1)\n",
    "    \n",
    "    # Predict SDF field for the \"average\" bone\n",
    "    sdf_pred_3d = model(xz_tensor_3d, latent_expanded).cpu().numpy().flatten()\n",
    "\n",
    "print(f\"‚úÖ Mean shape SDF generation complete\")\n",
    "print(f\"   ‚Ä¢ SDF range: [{sdf_pred_3d.min():.4f}, {sdf_pred_3d.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# SURFACE EXTRACTION: Extract average bone geometry\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üî∫ Extracting average bone surface using marching cubes...\")\n",
    "\n",
    "# Extract zero level set ‚Üí average bone surface\n",
    "mean_bone_mesh = grid.contour([0], sdf_pred_3d, method='marching_cubes')\n",
    "mean_bone_mesh.compute_normals(inplace=True)\n",
    "\n",
    "# =============================================================================\n",
    "# COMPARISON VISUALIZATION: Mean vs. individual reference bone\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Create visualization showing:\n",
    "# 1. Population average bone (generated from mean latent)\n",
    "# 2. Reference individual bone slice (for comparison)\n",
    "original_slice = list_tibs[0].slice('y')  # Use first bone as reference\n",
    "view(geometries=[mean_bone_mesh, original_slice])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed40f1c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéâ Tutorial Complete: Generative Shape Modeling Achieved!\n",
    "\n",
    "### üöÄ What We Accomplished\n",
    "\n",
    "Congratulations! You've successfully built and trained a **generative neural shape model** that can represent multiple bone shapes in a single network. This is a significant step up from Tutorial #1!\n",
    "\n",
    "### üèÜ Key Achievements\n",
    "\n",
    "**1. Multi-Shape Learning** ü¶¥\n",
    "- Loaded and registered 5 different tibia bones from different patients\n",
    "- Aligned them into a consistent coordinate system for shared learning\n",
    "\n",
    "**2. Generative Architecture** üß†\n",
    "- Built latent embedding layer to encode shape identity\n",
    "- Enhanced MLP to process coordinates + shape embeddings\n",
    "- Learned both shared anatomical patterns AND individual variations\n",
    "\n",
    "**3. Advanced Training** üìà\n",
    "- Multi-shape dataset with bone identity tracking\n",
    "- Extended training (40K epochs) for generative learning\n",
    "- Regularized latent codes to encourage smooth shape space\n",
    "\n",
    "**4. Shape Reconstruction** üé®\n",
    "- Demonstrated reconstruction of specific bones via latent codes\n",
    "- Visualized learned SDF fields across spatial domains\n",
    "- Extracted high-quality surfaces using marching cubes\n",
    "\n",
    "**5. Shape Space Exploration** üß¨\n",
    "- Generated population average bone using latent arithmetic\n",
    "- Demonstrated canonical shape generation and latent space analysis\n",
    "- Explored the center of the learned shape space\n",
    "\n",
    "### üéØ From Tutorial #1 to Tutorial #2\n",
    "\n",
    "| Aspect | Tutorial #1 (Single Shape) | Tutorial #2 (Generative) |\n",
    "|--------|----------------------------|---------------------------|\n",
    "| **Input** | `f(x,z) ‚Üí SDF` | `f(x,z,latent) ‚Üí SDF` |\n",
    "| **Capacity** | One specific bone | Multiple bone shapes |\n",
    "| **Training Data** | 40K points from 1 bone | 100K+ points from 5 bones |\n",
    "| **Applications** | Surface fitting | Shape generation & interpolation |\n",
    "| **Generalization** | Fixed geometry | Variable anatomy |\n",
    "| **Shape Space** | Single point | Multi-dimensional space |\n",
    "\n",
    "### üß™ Next Steps & Advanced Explorations\n",
    "\n",
    "**Shape Interpolation** üåü\n",
    "```python\n",
    "# Blend between two different bones\n",
    "latent_A = lat_vecs(torch.tensor(0))  # Patient A\n",
    "latent_B = lat_vecs(torch.tensor(1))  # Patient B\n",
    "latent_hybrid = 0.7 * latent_A + 0.3 * latent_B  # 70% A, 30% B\n",
    "# Use latent_hybrid to generate a morphed bone shape!\n",
    "```\n",
    "\n",
    "**Shape Space Analysis** üìä\n",
    "- Compute distances between latent codes ‚Üí bone similarity analysis\n",
    "- Principal Component Analysis on latent vectors ‚Üí major shape variation modes\n",
    "- Clustering latent codes ‚Üí discover bone types/populations\n",
    "\n",
    "**Novel Shape Generation** üé≤\n",
    "- Sample random latent vectors ‚Üí generate entirely new bone variations\n",
    "- Conditional generation based on patient metadata (age, gender, etc.)\n",
    "- Shape completion: predict missing bone regions\n",
    "\n",
    "**Scaling to Full 3D** üåç\n",
    "- Extend to full 3D coordinates (x,y,z) instead of 2D slices\n",
    "- Higher resolution grids for detailed reconstructions\n",
    "- Multiple anatomical structures (femur, humerus, etc.)\n",
    "\n",
    "\n",
    "- **Virtual reality**: Haptic interaction with anatomical models\n",
    "\n",
    "### üí° Research Directions\n",
    "\n",
    "This tutorial demonstrates the foundations of **neural implicit shape modeling** - a rapidly advancing field with connections to:\n",
    "\n",
    "- **3D Deep Learning**: Point clouds, voxels, meshes\n",
    "- **Generative AI**: VAEs, GANs, diffusion models for 3D\n",
    "- **Medical AI**: Shape-based diagnosis and treatment planning\n",
    "- **Computer Vision**: 3D reconstruction from images\n",
    "\n",
    "### üéì Key Takeaways\n",
    "\n",
    "1. **Latent embeddings** enable single networks to represent multiple shapes\n",
    "2. **Registration and normalization** are critical for multi-shape learning\n",
    "3. **Regularization** promotes smooth, interpolatable shape spaces\n",
    "4. **Neural SDFs** provide continuous, resolution-independent shape representation\n",
    "5. **Generative modeling** opens doors to shape synthesis and analysis\n",
    "6. **Shape space arithmetic** enables semantic manipulation of 3D geometry\n",
    "\n",
    "You now have the tools to build sophisticated generative shape models for your own applications. Whether in medical imaging, computer graphics, or beyond - the principles learned here provide a strong foundation for neural 3D modeling!\n",
    "\n",
    "**Happy generating!** üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isb_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
